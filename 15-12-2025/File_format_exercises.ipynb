{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4ov6JFySt8E"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "      .appName(\"File_format_exercises\") \\\n",
        "      .getOrCreate()\n",
        "\n",
        "\n",
        "data = \"\"\"\n",
        "order_id,customer_name,city,restaurant,cuisine,order_amount,delivery_time_minutes,payment_mode,order_status\n",
        "O001,Amit,Hyderabad,Spice Hub,Indian,450,35,UPI,Delivered\n",
        "O002,Neha,Bangalore,Pizza Town,Italian,650,40,Card,Delivered\n",
        "O003,Rahul,Delhi,Burger Zone,American,520,30,Cash,Delivered\n",
        "O004,Pooja,Mumbai,Sushi Bar,Japanese,1200,55,UPI,Cancelled\n",
        "O005,Arjun,Chennai,Curry Leaf,Indian,380,28,UPI,Delivered\n",
        "O006,Sneha,Hyderabad,Pasta Street,Italian,700,45,Card,Delivered\n",
        "O007,Karan,Delhi,Taco Bell,Mexican,540,33,UPI,Delivered\n",
        "O008,Riya,Bangalore,Dragon Bowl,Chinese,600,38,Wallet,Delivered\n",
        "O009,Vikas,Mumbai,BBQ Nation,Indian,1500,60,Card,Delivered\n",
        "O010,Anjali,Chennai,Burger Zone,American,480,32,Cash,Delivered\n",
        "O011,Farhan,Delhi,Biryani House,Indian,520,36,UPI,Delivered\n",
        "O012,Megha,Hyderabad,Sushi Bar,Japanese,1100,58,Card,Cancelled\n",
        "O013,Suresh,Bangalore,Curry Leaf,Indian,420,29,UPI,Delivered\n",
        "O014,Divya,Mumbai,Pizza Town,Italian,780,42,Wallet,Delivered\n",
        "O015,Nikhil,Delhi,Pasta Street,Italian,690,47,UPI,Delivered\n",
        "O016,Kavya,Chennai,Dragon Bowl,Chinese,560,34,UPI,Delivered\n",
        "O017,Rohit,Hyderabad,BBQ Nation,Indian,1400,62,Card,Delivered\n",
        "O018,Simran,Bangalore,Burger Zone,American,510,31,Cash,Delivered\n",
        "O019,Ayesha,Mumbai,Taco Bell,Mexican,570,35,UPI,Delivered\n",
        "O020,Manish,Delhi,Curry Leaf,Indian,390,27,Wallet,Delivered\n",
        "O021,Priya,Hyderabad,Pizza Town,Italian,720,41,Card,Delivered\n",
        "O022,Yash,Chennai,Sushi Bar,Japanese,1150,57,UPI,Delivered\n",
        "O023,Naina,Bangalore,Pasta Street,Italian,680,44,UPI,Delivered\n",
        "O024,Sameer,Mumbai,Dragon Bowl,Chinese,610,39,Wallet,Delivered\n",
        "O025,Ritika,Delhi,Burger Zone,American,500,30,Cash,Delivered\n",
        "O026,Gopal,Hyderabad,Curry Leaf,Indian,410,28,UPI,Delivered\n",
        "O027,Tina,Bangalore,Pizza Town,Italian,760,43,Card,Delivered\n",
        "O028,Irfan,Mumbai,BBQ Nation,Indian,1550,65,Card,Delivered\n",
        "O029,Sahil,Chennai,Taco Bell,Mexican,590,37,UPI,Delivered\n",
        "O030,Lavanya,Delhi,Dragon Bowl,Chinese,630,40,Wallet,Delivered\n",
        "O031,Deepak,Hyderabad,Burger Zone,American,520,33,Cash,Delivered\n",
        "O032,Shweta,Bangalore,Curry Leaf,Indian,450,31,UPI,Delivered\n",
        "O033,Aman,Mumbai,Pizza Town,Italian,810,46,Card,Delivered\n",
        "O034,Rekha,Chennai,Pasta Street,Italian,700,45,UPI,Delivered\n",
        "O035,Zubin,Delhi,BBQ Nation,Indian,1480,63,Card,Delivered\n",
        "O036,Pallavi,Hyderabad,Dragon Bowl,Chinese,580,36,Wallet,Delivered\n",
        "O037,Naveen,Bangalore,Taco Bell,Mexican,560,34,UPI,Delivered\n",
        "O038,Sonia,Mumbai,Sushi Bar,Japanese,1180,59,Card,Delivered\n",
        "O039,Harish,Chennai,Burger Zone,American,490,29,Cash,Delivered\n",
        "O040,Kriti,Delhi,Curry Leaf,Indian,420,26,UPI,Delivered\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write the full dataset to CSV with header enabled."
      ],
      "metadata": {
        "id": "nm6SFC6mVN_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"orders.csv\", \"w\") as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "Mw-MdEWVTrCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Read the CSV back and filter: order_amount > 700"
      ],
      "metadata": {
        "id": "SIMm7eYBVqJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read \\\n",
        "   .option(\"header\",True) \\\n",
        "   .option(\"interSchema\",True) \\\n",
        "   .csv('orders.csv')\n",
        "\n",
        "df.filter(df.order_amount>700).show()"
      ],
      "metadata": {
        "id": "y5NvB8WTJggH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdb4bc3-a667-4889-f2bb-5a2ff63bba41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+---------+----------+--------+------------+---------------------+------------+------------+\n",
            "|order_id|customer_name|     city|restaurant| cuisine|order_amount|delivery_time_minutes|payment_mode|order_status|\n",
            "+--------+-------------+---------+----------+--------+------------+---------------------+------------+------------+\n",
            "|    O004|        Pooja|   Mumbai| Sushi Bar|Japanese|        1200|                   55|         UPI|   Cancelled|\n",
            "|    O009|        Vikas|   Mumbai|BBQ Nation|  Indian|        1500|                   60|        Card|   Delivered|\n",
            "|    O012|        Megha|Hyderabad| Sushi Bar|Japanese|        1100|                   58|        Card|   Cancelled|\n",
            "|    O014|        Divya|   Mumbai|Pizza Town| Italian|         780|                   42|      Wallet|   Delivered|\n",
            "|    O017|        Rohit|Hyderabad|BBQ Nation|  Indian|        1400|                   62|        Card|   Delivered|\n",
            "|    O021|        Priya|Hyderabad|Pizza Town| Italian|         720|                   41|        Card|   Delivered|\n",
            "|    O022|         Yash|  Chennai| Sushi Bar|Japanese|        1150|                   57|         UPI|   Delivered|\n",
            "|    O027|         Tina|Bangalore|Pizza Town| Italian|         760|                   43|        Card|   Delivered|\n",
            "|    O028|        Irfan|   Mumbai|BBQ Nation|  Indian|        1550|                   65|        Card|   Delivered|\n",
            "|    O033|         Aman|   Mumbai|Pizza Town| Italian|         810|                   46|        Card|   Delivered|\n",
            "|    O035|        Zubin|    Delhi|BBQ Nation|  Indian|        1480|                   63|        Card|   Delivered|\n",
            "|    O038|        Sonia|   Mumbai| Sushi Bar|Japanese|        1180|                   59|        Card|   Delivered|\n",
            "+--------+-------------+---------+----------+--------+------------+---------------------+------------+------------+\n",
            "\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_name: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- restaurant: string (nullable = true)\n",
            " |-- cuisine: string (nullable = true)\n",
            " |-- order_amount: string (nullable = true)\n",
            " |-- delivery_time_minutes: string (nullable = true)\n",
            " |-- payment_mode: string (nullable = true)\n",
            " |-- order_status: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. From CSV, show only:\n",
        "order_id\n",
        "city\n",
        "cuisine\n",
        "order_amount"
      ],
      "metadata": {
        "id": "4rhwh0oNfohL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read \\\n",
        "   .option(\"header\",True) \\\n",
        "   .option(\"interSchema\",True) \\\n",
        "   .csv('orders.csv')\n",
        "\n",
        "df.select(\"order_id\",\"city\",\"cuisine\", \"order_amount\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2sxeHRMXnE2",
        "outputId": "810eab1a-c078-4971-b697-2f3bf122118c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+--------+------------+\n",
            "|order_id|     city| cuisine|order_amount|\n",
            "+--------+---------+--------+------------+\n",
            "|    O001|Hyderabad|  Indian|         450|\n",
            "|    O002|Bangalore| Italian|         650|\n",
            "|    O003|    Delhi|American|         520|\n",
            "|    O004|   Mumbai|Japanese|        1200|\n",
            "|    O005|  Chennai|  Indian|         380|\n",
            "|    O006|Hyderabad| Italian|         700|\n",
            "|    O007|    Delhi| Mexican|         540|\n",
            "|    O008|Bangalore| Chinese|         600|\n",
            "|    O009|   Mumbai|  Indian|        1500|\n",
            "|    O010|  Chennai|American|         480|\n",
            "|    O011|    Delhi|  Indian|         520|\n",
            "|    O012|Hyderabad|Japanese|        1100|\n",
            "|    O013|Bangalore|  Indian|         420|\n",
            "|    O014|   Mumbai| Italian|         780|\n",
            "|    O015|    Delhi| Italian|         690|\n",
            "|    O016|  Chennai| Chinese|         560|\n",
            "|    O017|Hyderabad|  Indian|        1400|\n",
            "|    O018|Bangalore|American|         510|\n",
            "|    O019|   Mumbai| Mexican|         570|\n",
            "|    O020|    Delhi|  Indian|         390|\n",
            "+--------+---------+--------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Sort orders by delivery_time_minutes descending and write result to CSV"
      ],
      "metadata": {
        "id": "pgL-2vh3g7KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "sorted_df = df.orderBy(col(\"delivery_time_minutes\").desc())\n",
        "sorted_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dlgehb5NglNl",
        "outputId": "adb33596-348f-41f4-e248-28b86f688ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+---------+------------+--------+------------+---------------------+------------+------------+\n",
            "|order_id|customer_name|     city|  restaurant| cuisine|order_amount|delivery_time_minutes|payment_mode|order_status|\n",
            "+--------+-------------+---------+------------+--------+------------+---------------------+------------+------------+\n",
            "|    O028|        Irfan|   Mumbai|  BBQ Nation|  Indian|        1550|                   65|        Card|   Delivered|\n",
            "|    O035|        Zubin|    Delhi|  BBQ Nation|  Indian|        1480|                   63|        Card|   Delivered|\n",
            "|    O017|        Rohit|Hyderabad|  BBQ Nation|  Indian|        1400|                   62|        Card|   Delivered|\n",
            "|    O009|        Vikas|   Mumbai|  BBQ Nation|  Indian|        1500|                   60|        Card|   Delivered|\n",
            "|    O038|        Sonia|   Mumbai|   Sushi Bar|Japanese|        1180|                   59|        Card|   Delivered|\n",
            "|    O012|        Megha|Hyderabad|   Sushi Bar|Japanese|        1100|                   58|        Card|   Cancelled|\n",
            "|    O022|         Yash|  Chennai|   Sushi Bar|Japanese|        1150|                   57|         UPI|   Delivered|\n",
            "|    O004|        Pooja|   Mumbai|   Sushi Bar|Japanese|        1200|                   55|         UPI|   Cancelled|\n",
            "|    O015|       Nikhil|    Delhi|Pasta Street| Italian|         690|                   47|         UPI|   Delivered|\n",
            "|    O033|         Aman|   Mumbai|  Pizza Town| Italian|         810|                   46|        Card|   Delivered|\n",
            "|    O006|        Sneha|Hyderabad|Pasta Street| Italian|         700|                   45|        Card|   Delivered|\n",
            "|    O034|        Rekha|  Chennai|Pasta Street| Italian|         700|                   45|         UPI|   Delivered|\n",
            "|    O023|        Naina|Bangalore|Pasta Street| Italian|         680|                   44|         UPI|   Delivered|\n",
            "|    O027|         Tina|Bangalore|  Pizza Town| Italian|         760|                   43|        Card|   Delivered|\n",
            "|    O014|        Divya|   Mumbai|  Pizza Town| Italian|         780|                   42|      Wallet|   Delivered|\n",
            "|    O021|        Priya|Hyderabad|  Pizza Town| Italian|         720|                   41|        Card|   Delivered|\n",
            "|    O002|         Neha|Bangalore|  Pizza Town| Italian|         650|                   40|        Card|   Delivered|\n",
            "|    O030|      Lavanya|    Delhi| Dragon Bowl| Chinese|         630|                   40|      Wallet|   Delivered|\n",
            "|    O024|       Sameer|   Mumbai| Dragon Bowl| Chinese|         610|                   39|      Wallet|   Delivered|\n",
            "|    O008|         Riya|Bangalore| Dragon Bowl| Chinese|         600|                   38|      Wallet|   Delivered|\n",
            "+--------+-------------+---------+------------+--------+------------+---------------------+------------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "JSON\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "5. Write only “Delivered” orders to JSON."
      ],
      "metadata": {
        "id": "HyMVQdKyhkNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(col(\"order_status\")==\"Delivered\").write.mode(\"overwrite\").json(\"delivered_orders_json\")"
      ],
      "metadata": {
        "id": "JmqF7HhYhX1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Read JSON and filter:\n",
        "city = \"Mumbai\"\n",
        "payment_mode = \"Card\""
      ],
      "metadata": {
        "id": "aq10TuJTjFdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json(\"delivered_orders_json\")\n",
        "df.filter((df.city==\"Mumbai\") & (df.payment_mode==\"Card\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptjDa12wjBsy",
        "outputId": "d9588d1c-6673-47e4-e4c9-f95ee7ca4943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-------------+---------------------+------------+--------+------------+------------+----------+\n",
            "|  city| cuisine|customer_name|delivery_time_minutes|order_amount|order_id|order_status|payment_mode|restaurant|\n",
            "+------+--------+-------------+---------------------+------------+--------+------------+------------+----------+\n",
            "|Mumbai|  Indian|        Vikas|                   60|        1500|    O009|   Delivered|        Card|BBQ Nation|\n",
            "|Mumbai|  Indian|        Irfan|                   65|        1550|    O028|   Delivered|        Card|BBQ Nation|\n",
            "|Mumbai| Italian|         Aman|                   46|         810|    O033|   Delivered|        Card|Pizza Town|\n",
            "|Mumbai|Japanese|        Sonia|                   59|        1180|    O038|   Delivered|        Card| Sushi Bar|\n",
            "+------+--------+-------------+---------------------+------------+--------+------------+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Add a column:\n",
        "delivery_category\n",
        "Logic:\n",
        "delivery_time_minutes > 45 → \"Late\"\n",
        "else → \"OnTime\"\n",
        "Write output to JSON."
      ],
      "metadata": {
        "id": "7mNRmoOnk_id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "new_df=df.withColumn(\"delivery_category\", when (col(\"delivery_time_minutes\") >45,\"Late\").otherwise (\"OnTime\" ))\n",
        "new_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p70sKiwj_fK",
        "outputId": "19bcf6ae-65ee-4888-bdaf-e1c567704f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------+---------------------+------------+--------+------------+------------+-------------+-----------------+\n",
            "|     city| cuisine|customer_name|delivery_time_minutes|order_amount|order_id|order_status|payment_mode|   restaurant|delivery_category|\n",
            "+---------+--------+-------------+---------------------+------------+--------+------------+------------+-------------+-----------------+\n",
            "|Hyderabad|  Indian|         Amit|                   35|         450|    O001|   Delivered|         UPI|    Spice Hub|           OnTime|\n",
            "|Bangalore| Italian|         Neha|                   40|         650|    O002|   Delivered|        Card|   Pizza Town|           OnTime|\n",
            "|    Delhi|American|        Rahul|                   30|         520|    O003|   Delivered|        Cash|  Burger Zone|           OnTime|\n",
            "|  Chennai|  Indian|        Arjun|                   28|         380|    O005|   Delivered|         UPI|   Curry Leaf|           OnTime|\n",
            "|Hyderabad| Italian|        Sneha|                   45|         700|    O006|   Delivered|        Card| Pasta Street|           OnTime|\n",
            "|    Delhi| Mexican|        Karan|                   33|         540|    O007|   Delivered|         UPI|    Taco Bell|           OnTime|\n",
            "|Bangalore| Chinese|         Riya|                   38|         600|    O008|   Delivered|      Wallet|  Dragon Bowl|           OnTime|\n",
            "|   Mumbai|  Indian|        Vikas|                   60|        1500|    O009|   Delivered|        Card|   BBQ Nation|             Late|\n",
            "|  Chennai|American|       Anjali|                   32|         480|    O010|   Delivered|        Cash|  Burger Zone|           OnTime|\n",
            "|    Delhi|  Indian|       Farhan|                   36|         520|    O011|   Delivered|         UPI|Biryani House|           OnTime|\n",
            "|Bangalore|  Indian|       Suresh|                   29|         420|    O013|   Delivered|         UPI|   Curry Leaf|           OnTime|\n",
            "|   Mumbai| Italian|        Divya|                   42|         780|    O014|   Delivered|      Wallet|   Pizza Town|           OnTime|\n",
            "|    Delhi| Italian|       Nikhil|                   47|         690|    O015|   Delivered|         UPI| Pasta Street|             Late|\n",
            "|  Chennai| Chinese|        Kavya|                   34|         560|    O016|   Delivered|         UPI|  Dragon Bowl|           OnTime|\n",
            "|Hyderabad|  Indian|        Rohit|                   62|        1400|    O017|   Delivered|        Card|   BBQ Nation|             Late|\n",
            "|Bangalore|American|       Simran|                   31|         510|    O018|   Delivered|        Cash|  Burger Zone|           OnTime|\n",
            "|   Mumbai| Mexican|       Ayesha|                   35|         570|    O019|   Delivered|         UPI|    Taco Bell|           OnTime|\n",
            "|    Delhi|  Indian|       Manish|                   27|         390|    O020|   Delivered|      Wallet|   Curry Leaf|           OnTime|\n",
            "|Hyderabad| Italian|        Priya|                   41|         720|    O021|   Delivered|        Card|   Pizza Town|           OnTime|\n",
            "|  Chennai|Japanese|         Yash|                   57|        1150|    O022|   Delivered|         UPI|    Sushi Bar|             Late|\n",
            "+---------+--------+-------------+---------------------+------------+--------+------------+------------+-------------+-----------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Force JSON output to a single partition and observe number of files created"
      ],
      "metadata": {
        "id": "ano4ANCdmxvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_single = df.coalesce(1)\n",
        "\n",
        "output_path = \"output/orders_json_single\"\n",
        "df_single.write.mode(\"overwrite\").json(output_path)\n"
      ],
      "metadata": {
        "id": "H-J_wTjUl2u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Convert full dataset to Parquet."
      ],
      "metadata": {
        "id": "1khdtzkKp2yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.mode(\"overwrite\").parquet(\"orders.parquet\")"
      ],
      "metadata": {
        "id": "Dyox1Vmyp-PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Read Parquet and filter:\n",
        "cuisine = \"Indian\"\n",
        "order_amount > 500\n"
      ],
      "metadata": {
        "id": "AHtwII_wqGXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_parquet = spark.read.parquet(\"orders.parquet\")\n",
        "df_new1= df_parquet.filter((df_parquet.cuisine==\"Indian\")&(df_parquet.order_amount>500))\n",
        "df_new1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0llzHf2qDU6",
        "outputId": "2562a491-64a2-4e05-fd09-00305f877e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------------+---------------------+------------+--------+------------+------------+-------------+\n",
            "|     city|cuisine|customer_name|delivery_time_minutes|order_amount|order_id|order_status|payment_mode|   restaurant|\n",
            "+---------+-------+-------------+---------------------+------------+--------+------------+------------+-------------+\n",
            "|   Mumbai| Indian|        Vikas|                   60|        1500|    O009|   Delivered|        Card|   BBQ Nation|\n",
            "|    Delhi| Indian|       Farhan|                   36|         520|    O011|   Delivered|         UPI|Biryani House|\n",
            "|Hyderabad| Indian|        Rohit|                   62|        1400|    O017|   Delivered|        Card|   BBQ Nation|\n",
            "|   Mumbai| Indian|        Irfan|                   65|        1550|    O028|   Delivered|        Card|   BBQ Nation|\n",
            "|    Delhi| Indian|        Zubin|                   63|        1480|    O035|   Delivered|        Card|   BBQ Nation|\n",
            "+---------+-------+-------------+---------------------+------------+--------+------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Sort Parquet data by order_amount descending and write top 10 orders back to Parquet."
      ],
      "metadata": {
        "id": "Ob7qziA4sFos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_df = df_parquet.orderBy(col(\"order_amount\").desc())\n",
        "df_parquet.write.mode(\"overwrite\").parquet(\"Top_10_orders.parquet\")"
      ],
      "metadata": {
        "id": "jxwPIvPlqvrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Compare storage size of:\n",
        "CSV\n",
        "JSON\n",
        "Parquet"
      ],
      "metadata": {
        "id": "qaW-o0t6tGxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Parquet is smaller than CSV and JSON**\n",
        "\n",
        "**CSV:** Plain text, no compression, stores all columns for every row → largest size.\n",
        "**JSON:** Adds structural overhead (braces, quotes, keys for each record) → even larger than CSV for wide datasets.\n",
        "**Parquet:** Columnar format + compression (Snappy/Gzip) + encoding → smallest size.\n",
        "\n",
        "\n",
        "Typical Size Ratios (for the same dataset)\n",
        "\n",
        "Example for a 100 MB dataset:\n",
        "\n",
        "CSV: ~100 MB\n",
        "JSON: ~150–200 MB\n",
        "Parquet: ~30–50 MB"
      ],
      "metadata": {
        "id": "u-MwtYwPnkhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Convert:\n",
        "CSV → Parquet\n",
        "JSON → Parquet"
      ],
      "metadata": {
        "id": "Q84M-rAhvgGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"orders.csv\")\n",
        "csv_df.write.mode(\"overwrite\").parquet(\"orders_from_csv_parquet\")\n",
        "\n",
        "\n",
        "json_df = spark.read.json(\"delivered_orders_json\")\n",
        "json_df.write.mode(\"overwrite\").parquet(\"orders_from_json_parquet\")\n"
      ],
      "metadata": {
        "id": "HdaNRZS1sra9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Read Parquet and write it back as CSV using delimiter |"
      ],
      "metadata": {
        "id": "RpeGjIo3vUxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_parquet1 = spark.read.parquet(\"orders.parquet\")\n",
        "\n",
        "(\n",
        "    df_parquet1\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .option(\"header\", True)\n",
        "    .option(\"delimiter\", \"|\")\n",
        "    .csv(\"orders_csv\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "fQgPadi-vQqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Which cuisine generates the highest order_amount overall?"
      ],
      "metadata": {
        "id": "-PHXu6k7xbv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import col, sum, desc\n",
        "\n",
        "df1 = spark.read.option(\"header\", True).csv(\"orders.csv\")\n",
        "\n",
        "\n",
        "overall = (\n",
        "    df1.groupBy(\"cuisine\")\n",
        "       .agg(sum(\"order_amount\").alias(\"total_order_amount\"))\n",
        "       .orderBy(desc(\"total_order_amount\"))\n",
        ")\n",
        "\n",
        "overall.show(1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHjKHobuxXQn",
        "outputId": "a772ed75-33a8-4ae7-89ce-39d5f192ddb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|cuisine|total_order_amount|\n",
            "+-------+------------------+\n",
            "| Indian|            9370.0|\n",
            "+-------+------------------+\n",
            "only showing top 1 row\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Which city has the highest number of orders?\n"
      ],
      "metadata": {
        "id": "tprCgJLt5njl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import col, count, desc\n",
        "\n",
        "\n",
        "highest_orders = (\n",
        "    df1.groupBy(\"city\")\n",
        "       .agg(count(\"order_id\").alias(\"total_orders\"))\n",
        "       .orderBy(desc(\"total_orders\"))\n",
        ")\n",
        "\n",
        "highest_orders.show(1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IadpMMw225ZZ",
        "outputId": "28bc7f27-7899-454b-dd08-756f41c9bf63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+\n",
            "| city|total_orders|\n",
            "+-----+------------+\n",
            "|Delhi|           9|\n",
            "+-----+------------+\n",
            "only showing top 1 row\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Which payment mode is most frequently used?"
      ],
      "metadata": {
        "id": "_nlYwQOi614F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import col, count, desc\n",
        "\n",
        "\n",
        "highest_orders1 = (\n",
        "    df1.groupBy(\"payment_mode\")\n",
        "       .agg(count(\"order_id\").alias(\"total_orders_per_paymentmethod\"))\n",
        "       .orderBy(desc(\"total_orders_per_paymentmethod\"))\n",
        ")\n",
        "\n",
        "highest_orders1.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuvHB1sA6lJi",
        "outputId": "1ea0d287-1397-44fa-b685-bdedb585fe9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------------------+\n",
            "|payment_mode|total_orders_per_paymentmethod|\n",
            "+------------+------------------------------+\n",
            "|         UPI|                            17|\n",
            "+------------+------------------------------+\n",
            "only showing top 1 row\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. Why is Parquet the preferred format for analytics platforms like Databricks and BigQuery?**"
      ],
      "metadata": {
        "id": "DwYPzhpo81Eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parquet is the preferred format for analytics platforms like Databricks and BigQuery because of several key advantages:\n",
        "\n",
        " 1. Columnar Storage\n",
        "\n",
        "Parquet stores data column-wise instead of row-wise.\n",
        "This is ideal for analytical queries that often scan only a few columns (e.g., SELECT cuisine, SUM(order_amount)).\n",
        "Reduces I/O because only the required columns are read.\n",
        "\n",
        "\n",
        " 2. Efficient Compression\n",
        "\n",
        "Columnar data compresses better than row-based formats because values in the same column are similar.\n",
        "Parquet uses advanced compression algorithms (e.g., Snappy, Gzip) and encoding techniques like dictionary encoding.\n",
        "This results in smaller storage footprint and faster reads.\n",
        "\n",
        "\n",
        " 3. Schema Support\n",
        "\n",
        "Parquet files store rich schema information (data types, column names, metadata).\n",
        "This makes it easy for platforms like Databricks and BigQuery to infer structure without extra configuration.\n",
        "\n",
        "\n",
        " 4. Predicate Pushdown\n",
        "\n",
        "Parquet supports filtering at the storage level.\n",
        "Example: If you query WHERE cuisine = 'Indian', only relevant row groups are read.\n",
        "This drastically improves query performance.\n",
        "\n",
        "\n",
        " 5. Compatibility & Integration\n",
        "\n",
        "Parquet is an open standard supported by Spark, Hive, Presto, BigQuery, and many other tools.\n",
        "Works seamlessly with distributed systems and cloud storage (S3, ADLS, GCS).\n",
        "\n",
        "\n",
        " 6. Optimized for Big Data\n",
        "\n",
        "Handles large-scale datasets efficiently.\n",
        "Supports splittable files, enabling parallel processing across clusters.\n",
        "\n",
        "\n",
        "7. Cost Efficiency\n",
        "\n",
        "Smaller file sizes → lower storage costs.\n",
        "Less data scanned → reduced query costs in platforms like BigQuery (which charges per TB scanned)."
      ],
      "metadata": {
        "id": "2p1FUXFZ9f7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenge 1 :Repartition the dataset into 4 partitions and write to Parquet."
      ],
      "metadata": {
        "id": "q5Ngc9KA-Efj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_repartitioned = df1.repartition(4)\n",
        "df_repartitioned.write.mode(\"overwrite\").parquet(\"repartitioned_orders.parquet\")\n"
      ],
      "metadata": {
        "id": "qbQ8g_yz8QTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenge 2- Create a report dataset containing:\n",
        "city\n",
        "total_orders\n",
        "total_revenue\n",
        "Write it to Parquet"
      ],
      "metadata": {
        "id": "z7URpbE2_U4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_report = (\n",
        "    df1.groupBy(\"city\")\n",
        "      .agg(\n",
        "          count(\"*\").alias(\"total_orders\"),\n",
        "          sum(\"order_amount\").alias(\"total_revenue\")\n",
        "      )\n",
        "      .orderBy(\"city\")\n",
        ")\n",
        "\n",
        "(\n",
        "    city_report\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(\"city_report_parquet\")\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2qQtinuP_GyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0cik0uxyVf6c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}