{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Partitioning_Exercises\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "f6VBXSgK2o-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKQGIrVN2a4x",
        "outputId": "651c9557-7898-41a6-9c48-da79a579dc68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-----------+------------+---------+\n",
            "|order_id|     city|   category|order_amount|   status|\n",
            "+--------+---------+-----------+------------+---------+\n",
            "|    O001|Hyderabad|Electronics|        1200|Delivered|\n",
            "|    O002|    Delhi|   Clothing|         800|Delivered|\n",
            "|    O003|   Mumbai|Electronics|        1500|Cancelled|\n",
            "|    O004|Bangalore|    Grocery|         400|Delivered|\n",
            "|    O005|Hyderabad|    Grocery|         300|Delivered|\n",
            "|    O006|    Delhi|Electronics|        2000|Delivered|\n",
            "|    O007|   Mumbai|   Clothing|         700|Delivered|\n",
            "|    O008|Bangalore|Electronics|        1800|Delivered|\n",
            "|    O009|    Delhi|    Grocery|         350|Cancelled|\n",
            "|    O010|Hyderabad|   Clothing|         900|Delivered|\n",
            "+--------+---------+-----------+------------+---------+\n",
            "\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- order_amount: long (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (\"O001\",\"Hyderabad\",\"Electronics\",1200,\"Delivered\"),\n",
        "    (\"O002\",\"Delhi\",\"Clothing\",800,\"Delivered\"),\n",
        "    (\"O003\",\"Mumbai\",\"Electronics\",1500,\"Cancelled\"),\n",
        "    (\"O004\",\"Bangalore\",\"Grocery\",400,\"Delivered\"),\n",
        "    (\"O005\",\"Hyderabad\",\"Grocery\",300,\"Delivered\"),\n",
        "    (\"O006\",\"Delhi\",\"Electronics\",2000,\"Delivered\"),\n",
        "    (\"O007\",\"Mumbai\",\"Clothing\",700,\"Delivered\"),\n",
        "    (\"O008\",\"Bangalore\",\"Electronics\",1800,\"Delivered\"),\n",
        "    (\"O009\",\"Delhi\",\"Grocery\",350,\"Cancelled\"),\n",
        "    (\"O010\",\"Hyderabad\",\"Clothing\",900,\"Delivered\")\n",
        "]\n",
        "\n",
        "columns=[\"order_id\",\"city\",\"category\",\"order_amount\",\"status\"]\n",
        "\n",
        "df= spark.createDataFrame(data, columns)\n",
        "df.show()\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds_xPdZ23LDx",
        "outputId": "09607e2c-4993-4388-cce1-79f40358eb08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_repart= df.repartition(4)\n",
        "df_repart.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GRys4gv3PMl",
        "outputId": "bca87abb-83af-4269-d73e-fb23b7d1859a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_coalesce = df_repart.coalesce(1)\n",
        "df_coalesce.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jbE2NV23lbN",
        "outputId": "f88e93e8-f889-456f-bfd9-a13b2c90e016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ repartition() vs coalesce() in Spark\n",
        "1. repartition(numPartitions)\n",
        "\n",
        "What it does:\n",
        "Creates a new DataFrame with exactly numPartitions partitions.\n",
        "How:\n",
        "It shuffles the data across the cluster to evenly distribute rows among the specified number of partitions.\n",
        "When to use:\n",
        "\n",
        "When you increase the number of partitions (e.g., from 4 to 10).\n",
        "When you want better parallelism for large operations like joins or aggregations.\n",
        "\n",
        "\n",
        "Cost:\n",
        "Expensive because it involves a full shuffle of data.\n",
        "\n",
        "\n",
        "2. coalesce(numPartitions)\n",
        "\n",
        "What it does:\n",
        "Reduces the number of partitions without a full shuffle.\n",
        "How:\n",
        "It merges existing partitions into fewer partitions.\n",
        "When to use:\n",
        "\n",
        "When you decrease the number of partitions (e.g., from 10 to 4).\n",
        "When you want to avoid unnecessary shuffling.\n",
        "\n",
        "\n",
        "Cost:\n",
        "Much cheaper than repartition() because it avoids a full shuffle.\n",
        "\n",
        "\n",
        "✅ Performance Impact\n",
        "\n",
        "Too few partitions:\n",
        "Tasks become large → less parallelism → slower execution.\n",
        "Too many partitions:\n",
        "Overhead in task scheduling → small tasks → inefficient.\n",
        "Rule of thumb:\n",
        "Aim for 128 MB per partition for optimal performance."
      ],
      "metadata": {
        "id": "ucqLpUL_5lcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the Transformation part\n",
        "filtered_df = df.filter(df.city==\"Delhi\")\n",
        "selected_df = filtered_df.select(\"order_id\",\"order_amount\")"
      ],
      "metadata": {
        "id": "kDcB5G-187BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the Action Part\n",
        "selected_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eac5FTi9Ztj",
        "outputId": "1681c499-3fe6-4c41-f958-4c9d4b16a18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------+\n",
            "|order_id|order_amount|\n",
            "+--------+------------+\n",
            "|    O002|         800|\n",
            "|    O006|        2000|\n",
            "|    O009|         350|\n",
            "+--------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the transformation part: where it is transformed but won't be printed until its acted upon\n",
        "df_lineage = (\n",
        "    df.filter(df.status==\"Delivered\")\n",
        "    .filter(df.order_amount>500)\n",
        "    .select(\"city\",\"order_amount\")\n",
        ")"
      ],
      "metadata": {
        "id": "38N0Acx59dC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is action part that prints the part it remembered in the transformation part in a way we want\n",
        "df_lineage.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeSX45J8-Ccv",
        "outputId": "86c8b9db-8f10-4db0-f588-b28947739627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlAzF1qu-FJ0",
        "outputId": "01407a3c-e157-4f73-e7ad-7c8a88168e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "LogicalRDD [order_id#0, city#1, category#2, order_amount#3L, status#4], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, city: string, category: string, order_amount: bigint, status: string\n",
            "LogicalRDD [order_id#0, city#1, category#2, order_amount#3L, status#4], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "LogicalRDD [order_id#0, city#1, category#2, order_amount#3L, status#4], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Scan ExistingRDD[order_id#0,city#1,category#2,order_amount#3L,status#4]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain shows the 4 stages through which the data passes through Spark\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I8djkysv_pvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_lineage.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7Oupt1hAOwK",
        "outputId": "6a6d4d29-34de-44d2-c0d8-7926904b43c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Project ['city, 'order_amount]\n",
            "+- Filter (order_amount#3L > cast(500 as bigint))\n",
            "   +- Filter (status#4 = Delivered)\n",
            "      +- LogicalRDD [order_id#0, city#1, category#2, order_amount#3L, status#4], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, order_amount: bigint\n",
            "Project [city#1, order_amount#3L]\n",
            "+- Filter (order_amount#3L > cast(500 as bigint))\n",
            "   +- Filter (status#4 = Delivered)\n",
            "      +- LogicalRDD [order_id#0, city#1, category#2, order_amount#3L, status#4], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#1, order_amount#3L]\n",
            "+- Filter ((isnotnull(status#4) AND isnotnull(order_amount#3L)) AND ((status#4 = Delivered) AND (order_amount#3L > 500)))\n",
            "   +- LogicalRDD [order_id#0, city#1, category#2, order_amount#3L, status#4], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [city#1, order_amount#3L]\n",
            "+- *(1) Filter ((isnotnull(status#4) AND isnotnull(order_amount#3L)) AND ((status#4 = Delivered) AND (order_amount#3L > 500)))\n",
            "   +- *(1) Scan ExistingRDD[order_id#0,city#1,category#2,order_amount#3L,status#4]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For lineage df it shows more plans as the data is selected twice and filtered before its output is shown"
      ],
      "metadata": {
        "id": "Ubzkn848AWbn"
      }
    }
  ]
}